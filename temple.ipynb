import pandas as pd
from sklearn.preprocessing import OneHotEncoder, StandardScaler
from sklearn.cluster import KMeans
from sklearn.metrics import silhouette_score
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.preprocessing import LabelEncoder
from collections import Counter
import matplotlib as mpl

plt.rcParams["font.family"] = "Malgun Gothic"   # 한글 글꼴 지정
mpl.rcParams["axes.unicode_minus"] = False


df = pd.read_csv('2024_tourism_data_utf8.csv')

df = df[df['Q1'].isin([1, 2])]

main_cols = ['Q1','D_AGE','D_NAT','D_MOK','R일HAP','Q8_1a1', 'Q8_1a2', 'Q8_1a3']
# Q8_1a1 ~ Q8_1a3 (만족한 활동)
# Q8a01 ~ Q8a20 (참여한 활동) 컬럼 
q8a_cols = [f'Q8a{i:02d}' for i in range(1, 21)]
# Q12a01 ~ Q12a27 (항목별 만족도) 컬럼 
q12a_cols = [f'Q12a{i:02d}' for i in range(1, 28)]
# Q9_2a01 ~ Q9_2a17 (방문지역) 컬럼 
q9_2a_cols = [f'Q9_2a{str(i).zfill(2)}' for i in range(1, 18)]


all_cols = main_cols + q8a_cols + q12a_cols + q9_2a_cols

df_cols['활동_선택목록'] = df_cols[q8a_cols].apply(
    lambda row: [int(x) for x in row if not pd.isnull(x)],
    axis=1)

df_cols[['활동_선택목록']]

df_cols['항목별 만족도'] = df_cols[q12a_cols].apply(
    lambda row: [int(x) for x in row if not pd.isnull(x)],
    axis=1)

df_cols[['항목별 만족도']]

df_cols['방문지역'] = df_cols[q9_2a_cols].apply(
    lambda row: [int(x) for x in row if not pd.isnull(x)],
    axis=1)

df_cols[['방문지역']]

df_cols[q8a_cols + q12a_cols + q9_2a_cols] = df_cols[q8a_cols + q12a_cols + q9_2a_cols].fillna(0).astype(int)

# main_cols에서 레이블 인코딩할 컬럼을 제외한 나머지를 원-핫 인코딩할 컬럼으로 지정
one_hot_cols_base = ['Q8_1a1', 'Q8_1a2', 'Q8_1a3'] + q8a_cols + q12a_cols + q9_2a_cols

label_encode_cols = ['D_AGE','D_NAT','D_MOK','R일HAP']
selected_cols = one_hot_cols_base + label_encode_cols
df_processed = df_cols[selected_cols].copy()

# 원-핫 인코딩 후 숫자 변환
df_encoded = pd.get_dummies(df_processed, columns=one_hot_cols_base)
df_encoded = df_encoded.astype(int)

# 라벨 인코딩 (나이, 국적 등 범주형 → 숫자)
encoder = LabelEncoder()
for col in label_encode_cols:
    df_encoded[col] = encoder.fit_transform(df_encoded[col].astype(str))

df_cleaned = df_encoded.loc[:, ~df_encoded.applymap(type).eq(list).any()]
correlations = df_cleaned.corr()
print(correlations)


print(df_encoded.columns.tolist())


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.decomposition import PCA
from sklearn.metrics import silhouette_score

# 1. 입력 데이터
X = df_encoded.copy()

# 2. 스케일링
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 3. 군집 알고리즘들
kmeans = KMeans(n_clusters=4, random_state=42)
kmeans_labels = kmeans.fit_predict(X_scaled)

dbscan = DBSCAN(eps=0.5, min_samples=5)
dbscan_labels = dbscan.fit_predict(X_scaled)

agg = AgglomerativeClustering(n_clusters=4)
agg_labels = agg.fit_predict(X_scaled)

# 4. 실루엣 점수 비교 (DBSCAN은 -1 노이즈 있을 수 있음 주의)
kmeans_sil = silhouette_score(X_scaled, kmeans_labels)
dbscan_sil = silhouette_score(X_scaled, dbscan_labels)
agg_sil = silhouette_score(X_scaled, agg_labels)

print("=== 군집 결과 비교 ===")
print("KMeans: 실루엣 점수 =", kmeans_sil, "| 클러스터 라벨 =", np.unique(kmeans_labels))
print("DBSCAN: 실루엣 점수 =", dbscan_sil, "| 클러스터 라벨 =", np.unique(dbscan_labels))
print("Agglomerative: 실루엣 점수 =", agg_sil, "| 클러스터 라벨 =", np.unique(agg_labels))

# 5. PCA로 2차원 축소
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_scaled)

# 6. 시각화
fig, axes = plt.subplots(1, 3, figsize=(15, 4))

axes[0].scatter(X_pca[:, 0], X_pca[:, 1], c=kmeans_labels, cmap='tab10')
axes[0].set_title("KMeans")

axes[1].scatter(X_pca[:, 0], X_pca[:, 1], c=dbscan_labels, cmap='tab10')
axes[1].set_title("DBSCAN")

axes[2].scatter(X_pca[:, 0], X_pca[:, 1], c=agg_labels, cmap='tab10')
axes[2].set_title("Agglomerative")

plt.tight_layout()
plt.show()

# 7. KMeans 결과를 df_encoded에 저장
df_encoded['cluster'] = kmeans_labels

# 8. 각 군집의 평균값 보기
cluster_summary = df_encoded.groupby('cluster').mean(numeric_only=True)
print("=== KMeans 군집별 평균값 ===")
print(cluster_summary)



# 부산(Q9_2a13) 방문자만 추출
bosan = df_cols[df_cols['Q9_2a13'] == 13]

all_activities = sum(bosan['활동_선택목록'], [])  # 리스트 안의 리스트를 풀어서 하나로

# 빈도 세기
activity_counts = pd.Series(Counter(all_activities)).sort_values(ascending=False)

# 비율로 변환 (참여자 수로 나누면 '참여율'처럼 해석 가능)
activity_rate = activity_counts / len(bosan)

# 시각화
activity_rate.head(10).plot(kind='bar', title='부산 방문자 주요 활동')
plt.ylabel("참여율")
plt.show()

# 서울 방문자만 추출
seoul = df_cols[df_cols['Q9_2a01'] == 1]

all_activities = sum(seoul['활동_선택목록'], [])  # 리스트 안의 리스트를 풀어서 하나로

# 빈도 세기
activity_counts = pd.Series(Counter(all_activities)).sort_values(ascending=False)

# 비율로 변환 (참여자 수로 나누면 '참여율'처럼 해석 가능)
activity_rate = activity_counts / len(seoul)

# 시각화
activity_rate.head(10).plot(kind='bar', title='서울 방문자 주요 활동')
plt.ylabel("참여율")
plt.show()

# 경기 방문자만 추출
Gyeonggi = df_cols[df_cols['Q9_2a02'] == 2]

all_activities = sum(Gyeonggi['활동_선택목록'], [])  # 리스트 안의 리스트를 풀어서 하나로

# 빈도 세기
activity_counts = pd.Series(Counter(all_activities)).sort_values(ascending=False)

# 비율로 변환 (참여자 수로 나누면 '참여율'처럼 해석 가능)
activity_rate = activity_counts / len(Gyeonggi)

# 시각화
activity_rate.head(10).plot(kind='bar', title='경기 방문자 주요 활동')
plt.ylabel("참여율")
plt.show()


# 제주 방문자만 추출
jeju = df_cols[df_cols['Q9_2a17'] == 17]

all_activities = sum(jeju['활동_선택목록'], [])  # 리스트 안의 리스트를 풀어서 하나로

# 빈도 세기
activity_counts = pd.Series(Counter(all_activities)).sort_values(ascending=False)

# 비율로 변환 (참여자 수로 나누면 '참여율'처럼 해석 가능)
activity_rate = activity_counts / len(jeju)

# 시각화
activity_rate.head(10).plot(kind='bar', title='제주 방문자 주요 활동')
plt.ylabel("참여율")
plt.show()

'''
Q12a04 고궁/역사 유적지 방문  
Q12a05 전통문화체험 (한복체험, 태권도, 한국음식 만들기 등)
Q12a06 박물관, 전시관 관람

활동_선택목록 / 항목별 만족도
'''

from scipy.stats import ttest_ind

df_cols['참여여부'] = df_cols['활동_선택목록'].apply(lambda x: 5 in x if isinstance(x, list) else False)

# 만족도 점수가 0 이상인 사람만 비교 대상으로 사용
group_yes = df_cols[df_cols['참여여부'] == True]['Q12a05']
group_no = df_cols[df_cols['참여여부'] == False]['Q12a05']

# 평균 비교
print("평균(참여):", group_yes.mean())
print("평균(비참여):", group_no.mean())

# t-검정 (equal_var=False 추천)
t_stat, p_value = ttest_ind(group_yes, group_no, equal_var=False)
print("t-검정 결과: t =", t_stat, ", p =", p_value)



from scipy.stats import ttest_ind

# 결측치는 0으로 대체 (비참여로 간주)
df_cols['Q12a05_filled'] = df_cols['Q12a05'].fillna(0)

# 참여자 그룹은 '활동_선택목록' 안에 5가 포함된 사람
group_yes = df_cols[df_cols['활동_선택목록'].apply(lambda x: 5 in x)]['Q12a05_filled']

# 비참여자 그룹은 5가 포함되지 않은 사람
group_no = df_cols[df_cols['활동_선택목록'].apply(lambda x: 5 not in x)]['Q12a05_filled']

print("평균(참여):", group_yes.mean())
print("평균(비참여):", group_no.mean())

t_stat, p_val = ttest_ind(group_yes, group_no, equal_var=False)
print("t-검정 결과:", t_stat, p_val)



participants = df_cols[df_cols['활동_선택목록'].apply(lambda x: 5 in x)]
#만족도 기본 통계 확인
participants['Q12a05'].describe()
#방문 목적별
participants.groupby('D_MOK')['Q12a05'].mean().sort_values(ascending=False)
#나이대별
participants.groupby('D_AGE')['Q12a05'].mean().sort_values(ascending=False)
# 국적별 응답자 수가 10명 이상인 경우만 필터
nationality_counts = participants['D_NAT'].value_counts()
valid_nations = nationality_counts[nationality_counts >= 10].index

filtered = participants[participants['D_NAT'].isin(valid_nations)]
top_n = filtered.groupby('D_NAT')['Q12a05'].mean().sort_values(ascending=False).head(10)

import seaborn as sns
import matplotlib.pyplot as plt
#국적별 상위 10개국 만족도 시각화
sns.barplot(x=top_n.values, y=top_n.index)
plt.title("국적별 고궁 활동 만족도 (상위 10)")
plt.xlabel("평균 만족도")
plt.ylabel("국적")
plt.xlim(0, 5)
plt.show()



# 국적별 평균 만족도와 응답자 수 계산
summary_table = participants.groupby('D_NAT').agg(
    평균_만족도=('Q12a05', 'mean'),
    참여자_수=('Q12a05', 'count')
).sort_values(by='평균_만족도', ascending=False)

# 상위 10개국만 보기
summary_table.head(10)

# 17-몽골 
# 11-러시아
# 9-필리핀
# 4-미국
# 12-중동
# 13-인도네시아
# 15-호주
# 16-영국
# 97-기타




from sklearn.model_selection import train_test_split

# 데이터 준비
X = df.drop(columns=['Q11'])
y = df['Q11']

# 학습/테스트 데이터 분리
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42)

# 랜덤 포레스트 회귀
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
import numpy as np

model = RandomForestRegressor(random_state=42)
model.fit(X_train, y_train)

y_pred = model.predict(X_test)

print("MSE:", mean_squared_error(y_test, y_pred))
print("RMSE:", np.sqrt(mean_squared_error(y_test, y_pred)))
print("R2 score:", r2_score(y_test, y_pred))
# 변수 중요도 확인
import matplotlib.pyplot as plt
import numpy as np

importances = model.feature_importances_
indices = np.argsort(importances)[::-1]

plt.figure(figsize=(10,6))
plt.title("Feature Importances")
plt.bar(range(len(X.columns)), importances[indices], align='center')
plt.xticks(range(len(X.columns)), [X.columns[i] for i in indices], rotation=90)
plt.tight_layout()
plt.show()

# 만족도 분포 확인
import seaborn as sns

sns.countplot(x=y)


